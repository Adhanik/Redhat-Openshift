
# Containers

Containers is a process that runs an application independently from other containers on the host machine. Containers are created from a container image, which includes all runtime dependencies of an application. Hence containers can be executed on any host, so there are no conflicts btw the dependency of diff containers.

## How do containers work?

Contaienrs use Linux kernel feature, such as ns and cgroups. Containers use cgroups for resource management, such as CPU time allocation and system memory. 

NS isolate a containers processes and resources from other contianers and host system.

# Kubernetes

KB is a container orchestration platform that simplifies deployment, management and scaling of containerized applications.

KB creates a cluster that run containerised applications across multiple nodes. if node fails, KB can restart an applicaton in diff node.

## Workload in KB

KB admin write a definition of workloads to execute in cluster, and KB defines workloads in terms of pods. A pod is one or multiple containers that run in the same cluster node to share some resources. 

Pods with multiple containers are useful in some situations, when two containers must run in same cluster node to share some resources. For eg, a job is a workload that runs a task in a pod until completion.

## Declarative approach

Declarative resource mgmt reduces the work to create workloads and improve maintainability. To support declarative resource mgmt, KB uses controller that continuously trach the state of the cluster and perform the necessary steps to keep the cluster in intended state.


## Architecture

In Kubernetes, the architecture is typically divided into **control plane nodes** and **compute plane nodes** (also known as **worker nodes**). Each node type has specific components and responsibilities:

---

### 1. **Control Plane Node** (Master Node)

The control plane node manages the overall Kubernetes cluster, handling tasks such as scheduling, cluster state management, and orchestrating pod lifecycle and services. Key components of the control plane include:

- **API Server**:
  - Acts as the entry point for all Kubernetes API interactions.
  - All external requests (from users or kubectl commands) and internal components (like kubelet) communicate with the API Server.
  - The API Server authenticates, validates, and processes requests before executing them.

- **etcd**:
  - A distributed, key-value store that serves as the "source of truth" for the cluster’s current state.
  - Stores all cluster data (e.g., configuration, state, network details).
  - Highly available and redundant to prevent data loss.

- **Scheduler**:
  - Assigns new pods to appropriate compute nodes (worker nodes) based on resource requirements and policies.
  - Optimizes pod placement to ensure the efficient use of resources across the cluster.

- **Controller Manager**:
  - Runs various controllers, each managing specific aspects of the cluster (e.g., node health, replication, endpoint updates).
  - Controllers are responsible for reconciling the actual state with the desired state (as defined by the user) by making necessary adjustments.

- **Cloud Controller Manager** (if deployed on a cloud provider):
  - Manages integration with cloud-specific services, such as load balancers, persistent volumes, and networking.
  - Ensures that cloud resources align with the state in Kubernetes.

---

### 2. **Compute Plane Nodes** (Worker Nodes)

Compute plane nodes are responsible for running the actual application workloads in the form of pods. Each worker node has several components that allow it to communicate with the control plane, manage workloads, and provide the required networking.

- **Kubelet**:
  - An agent that runs on each worker node and communicates with the API Server.
  - Ensures that containers defined in pods are running and healthy according to the pod specifications.
  - Regularly checks on pod health and reports node status back to the control plane.

- **Kube-proxy**:
  - Manages network rules on each node, allowing services within the cluster to communicate.
  - Sets up IP tables or IPVS (depending on the configuration) to forward requests to appropriate pod endpoints.
  - Handles load balancing for service traffic across the pods within a service.

- **Container Runtime**:
  - Manages container lifecycle and provides an environment for container execution.
  - Kubernetes supports multiple runtimes, including Docker, containerd, and CRI-O.
  - Kubelet uses the container runtime to launch, manage, and stop containers as defined by Kubernetes.

---

### **Control Plane and Compute Plane Interaction**

1. **Scheduling**:
   - The control plane (scheduler) decides which nodes will run new pods based on resource availability and constraints.

2. **Pod Lifecycle Management**:
   - Controllers in the control plane ensure that the desired number of pods, deployments, and other resources are maintained.

3. **Networking**:
   - The control plane manages networking between pods and services, while kube-proxy and other components on the worker nodes handle the actual data forwarding.

4. **State Management**:
   - All state information (node status, pod status, etc.) is sent from compute plane nodes to the control plane, which stores it in etcd.

By dividing responsibilities between the control plane and compute nodes, Kubernetes achieves a highly scalable, resilient, and modular architecture that enables centralized control and decentralized execution of workloads.




## Kubernetes Feature

1. Service Discovery and load balancing 

When we distribute applicatons over multiple nodes, it can complicate communication btw applications. KB automatically configures networking and provides a DNS service for pods. With this, pods can communicate with services from other pods transparently across nodes by using only hostnames instead of iP address.

EG - KB can evenly split incoming requests to an NGINX web server by considering availability of NGINX pod.

Are services absolute necessity for communication and networking? Look ans in service discovery and networking.md

2. Horizontal scaling 

KB can monitor the load on a service, and create or delete pods to adapt to the load. You define the desired number of pod replicas in a Deployment or ReplicaSet. Kubernetes automatically creates or deletes pods to maintain that replica count.

Kubernetes can monitor specific metrics, such as CPU or memory utilization, using the Horizontal Pod Autoscaler (HPA).
HPA adjusts the number of replicas dynamically, scaling up pods when the load increases and scaling down when the load decreases. It’s configured to target specific thresholds, such as "maintain CPU usage below 50% per pod."

3. Self-healing

If we have declare health checks on our applications, KB can monitor, restart, and reschedule failing.

4. Automated rollout

KB can gradually roll out updates to your applications containers. If anything goes wrong during rollout, KB can roll back to previous version of the deployment as well.

5. Secrets and Configuration management

We can also manage configuration settings and secrets of our app without requiring changes to container.


